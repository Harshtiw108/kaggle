{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training and testing datasets\ntrain_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ntest_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore the training data\ntrain_essays.info()\ntrain_essays.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for class balance\nsns.countplot(data=train_essays, x='generated')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text Preprocessing\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n    words = text.split()  # Tokenize\n    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n    words = [word for word in words if word not in stop_words]  # Remove stop words\n    return ' '.join(words)\n\ntrain_essays['clean_text'] = train_essays['text'].apply(clean_text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_essays['clean_text'], train_essays['generated'], test_size=0.2, random_state=42)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenization and Encoding for BERT\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, padding=True, truncation=True, max_length=128)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\nencoded_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors='pt')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to tensors\ntrain_labels = torch.tensor(y_train.values)\nval_labels = torch.tensor(y_val.values)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TensorDatasets\ntrain_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\nval_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoader for efficient processing\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and learning rate scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\nepochs = 10","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to avoid exploding gradients\n        optimizer.step()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation loop\nmodel.eval()\nval_preds = []\nval_labels = []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n        val_labels.extend(labels.cpu().numpy())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate validation accuracy\nval_accuracy = accuracy_score(val_labels, val_preds)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data processing\ntest_inputs = tokenizer(test_essays['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n\n# Move input tensor to the same device as the model\ntest_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n\n# Generate predictions using your trained model\nwith torch.no_grad():\n    outputs = model(**test_inputs)\n    logits = outputs.logits\n\n# Assuming the first column of logits corresponds to the negative class (non-AI-generated) \n# and the second column corresponds to the positive class (AI-generated)\npredictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Move predictions back to CPU\n\n# Create a submission DataFrame with essay IDs and corresponding predictions\nsubmission = pd.DataFrame({\n    'id': test_essays['id'],\n    'generated': predictions\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}